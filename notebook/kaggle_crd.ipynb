{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/mlg-ulb/creditcardfraud/downloads/creditcardfraud.zip/3\n",
    "df = pd.read_csv('creditcardfraud.zip')\n",
    "lgl = [df['Class'] == 0]\n",
    "frd = [df['Class'] == 1]\n",
    "print(df['Class'].value_counts())\n",
    "\n",
    "lgl = df[df['Class'] == 0].sample(frac=1)\n",
    "frd = df[df['Class'] == 1].sample(frac=1)\n",
    "lgt = lgl[:10000]\n",
    "frt = frd[:400]\n",
    "lgv = lgl[10000:10000 + 1000]\n",
    "frv = frd[400:]\n",
    "\n",
    "train = pd.concat([lgt,frt]).sample(frac=1)\n",
    "vald = pd.concat([lgv,frv]).sample(frac=1)\n",
    "Xt = train.iloc[:,:-1]\n",
    "yt = train.iloc[:,-1:].values.ravel()\n",
    "Xv = vald.iloc[:,:-1]\n",
    "yv = vald.iloc[:,-1:].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9880952380952381 \tmcc:  0.9206154520651885\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CP</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PP</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PN</th>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CP   CN\n",
       "PP  80    1\n",
       "PN  12  999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = MLPClassifier([30])\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "#clf = GradientBoostingClassifier()\n",
    "clf.fit(Xt, yt)\n",
    "y_pred = clf.predict(Xv)\n",
    "print('acc: ',accuracy_score(yv, y_pred), '\\tmcc: ', matthews_corrcoef(yv, y_pred))\n",
    "print('Confusion matrix:')\n",
    "pd.DataFrame(confusion_matrix(yv, y_pred, [1,0]).T, index=['PP','PN'], columns=['CP','CN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9844322344322345 \tmcc:  0.8951900606298095\n",
      "Train:  auc-> 1.0 \taucpr-> 1.0\n",
      "Eval: auc-> 0.979804 \taucpr-> 0.932696\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CP</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PP</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PN</th>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CP   CN\n",
       "PP  76    1\n",
       "PN  16  999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(Xt, label=yt)\n",
    "dval = xgb.DMatrix(Xv, label=yv)\n",
    "dtest = xgb.DMatrix(Xv)\n",
    "param = {'nthread':8, 'seed':0, 'objective':'binary:logistic', 'max_depth':15, 'eta':0.1, 'booster':'gbtree'}\n",
    "param['eval_metric'] = ['auc','aucpr']\n",
    "watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "num_round = 200\n",
    "evals_result = {}\n",
    "clf = xgb.train(param, dtrain, num_round, watchlist, early_stopping_rounds=None, evals_result=evals_result, verbose_eval=0)\n",
    "#bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\n",
    "#bst.predict(dtest, ntree_limit=num_round)\n",
    "\n",
    "y_pred = np.where(clf.predict(dtest) < .5, 0, 1)\n",
    "print('acc: ',accuracy_score(yv, y_pred), '\\tmcc: ', matthews_corrcoef(yv, y_pred))\n",
    "print('Train: ','auc->',evals_result['train']['auc'][-1], '\\taucpr->', evals_result['train']['aucpr'][-1])\n",
    "print('Eval:' , 'auc->', evals_result['eval']['auc'][-1], '\\taucpr->', evals_result['eval']['aucpr'][-1])\n",
    "print('Confusion matrix:')\n",
    "pd.DataFrame(confusion_matrix(yv, y_pred, [1,0]).T, index=['PP','PN'], columns=['CP','CN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Columns order:',\n",
       " 'Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Xv.to_csv('test.csv', header=None, index=False)\n",
    "Xv.to_json('test.json', orient='records', lines=True)\n",
    "clf.save_model('model.xgb')\n",
    "\"Columns order:\", '\",\"'.join(Xv.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow basic estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9853479853479854 \tmcc:  0.9016536382569664\n",
      "Confusion matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CP</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PP</th>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PN</th>\n",
       "      <td>14</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CP   CN\n",
       "PP  78    2\n",
       "PN  14  998"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x_train, y_train, x_test, y_test = Xt, yt, Xv, yv\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_dim=x_train.shape[1]),\n",
    "#     tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')#, metrics=['accuracy']\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, verbose=0, batch_size=128)\n",
    "#model.evaluate(x_test, y_test)\n",
    "#model.save('teste.mod')\n",
    "#model2 = tf.keras.models.load_model('teste.mod')\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print('acc: ', accuracy_score(y_test, y_pred), '\\tmcc: ', matthews_corrcoef(y_test, y_pred))\n",
    "print('Confusion matrix:\\n')\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred, [1,0]).T, index=['PP','PN'], columns=['CP','CN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow boosted tree estimator\n",
    "https://www.tensorflow.org/tutorials/estimators/boosted_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 20:17:02.725621 139660223960896 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpd6c4gnf7\n",
      "W0723 20:17:03.756095 139660223960896 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0723 20:17:05.402199 139660223960896 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0723 20:17:05.585092 139660223960896 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "W0723 20:17:06.962818 139660223960896 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "W0723 20:17:14.411398 139660223960896 meta_graph.py:449] Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9908424908424909 \tmcc:  0.9394038281288066\n",
      "Confusion matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CP</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PP</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PN</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CP    CN\n",
       "PP  82     0\n",
       "PN  10  1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EXAMPLES = len(y_train)\n",
    "NUMERIC_COLUMNS = x_train.columns\n",
    "feature_columns = []\n",
    "fc = tf.feature_column\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(fc.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
    "\tdef input_fn():\n",
    "\t\tdataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
    "\t\tif shuffle:\n",
    "\t\t\tdataset = dataset.shuffle(NUM_EXAMPLES)\n",
    "\t\t# For training, cycle thru dataset as many times as need (n_epochs=None).\n",
    "\t\tdataset = dataset.repeat(n_epochs)\n",
    "\t\t# In memory training doesn't use batching.\n",
    "\t\tdataset = dataset.batch(NUM_EXAMPLES)\n",
    "\t\treturn dataset\n",
    "\treturn input_fn\n",
    "\n",
    "'''\n",
    "# Since data fits into memory, use entire dataset per layer. It will be faster.\n",
    "# Above one batch is defined as the entire dataset.\n",
    "n_batches = 1\n",
    "est = tf.estimator.BoostedTreesClassifier(feature_columns,\n",
    "                                          n_batches_per_layer=n_batches)\n",
    "\n",
    "# The model will stop training once the specified number of trees is built, not\n",
    "# based on the number of steps.\n",
    "est.train(train_input_fn, max_steps=100)\n",
    "\n",
    "# Eval.\n",
    "results = est.evaluate(eval_input_fn)\n",
    "print('Accuracy : ', results['accuracy'])\n",
    "print('Dummy model: ', results['accuracy_baseline'])\n",
    "'''\n",
    "\n",
    "def make_inmemory_train_input_fn(X, y):\n",
    "    def input_fn():\n",
    "        return dict(X), y\n",
    "    return input_fn\n",
    "\n",
    "train_input_fn = make_inmemory_train_input_fn(x_train, y_train)\n",
    "eval_input_fn = make_input_fn(x_test, y_test, shuffle=False, n_epochs=1)\n",
    "est = tf.contrib.estimator.boosted_trees_classifier_train_in_memory(train_input_fn,feature_columns)\n",
    "\n",
    "pred_dicts = list(est.predict(eval_input_fn))\n",
    "y_pred = [x['class_ids'][0] for x in pred_dicts]\n",
    "print('acc: ', accuracy_score(y_test, y_pred), '\\tmcc: ', matthews_corrcoef(y_test, y_pred))\n",
    "print('Confusion matrix:\\n')\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred, [1,0]).T, index=['PP','PN'], columns=['CP','CN'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
